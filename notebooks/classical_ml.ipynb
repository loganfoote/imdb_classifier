{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8629f04e-9c61-4344-ab8c-fa49aeb4814e",
   "metadata": {},
   "source": [
    "# IMDb Movie Review Classifications \n",
    "The aim of this project is to classify IMDb movie reviews as negative or positive. As a first approach, I use classical ML models to classify reviews. I am using the IMDb review dataset from [Maas et al. 2011](http://www.aclweb.org/anthology/P11-1015), which contains highly polar reviews and their classifications (25,000 training reviews, 25,000 testing reviews). The reviews are vectorize, and then several classical models are trained to compare performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b2519d-954f-4c4f-9762-48af60e0d38f",
   "metadata": {},
   "source": [
    "## Data loading and EDA\n",
    "The training and test datasets are loaded into pandas DataFrames. The first few lines of each dataset are printed and the distribution of negative and positive reviews are plotted to confirm the data structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbeb37f-4f4a-41ab-a26c-cd5372ed07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imdb_classification.data import load_imdb_data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c3565e-b042-484a-8caf-cf584ee11e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'imdb_classifier/data/' # Replace\n",
    "data_train = load_imdb_data(data_dir, subset = 'train')\n",
    "data_test = load_imdb_data(data_dir, subset = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a53e89-7578-4b0a-abd2-da24311e22e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_train.head())\n",
    "print(data_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa8bda8-8fed-44bd-93c5-67ab8d2b9b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = [10, 4], layout = 'tight')\n",
    "axs[0].set_title('Distribution of negative (0) and positive (1) \\nreviews in train data')\n",
    "axs[1].set_title('Distribution of negative (0) and positive (1) \\nreviews in test data')\n",
    "\n",
    "_ = sns.countplot(data_train, x = 'label', color = plt.cm.viridis(0.), ax = axs[0])\n",
    "_ = sns.countplot(data_test, x = 'label', color = plt.cm.viridis(0.), ax = axs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd419d5-7951-41c7-9397-e6bc4227d301",
   "metadata": {},
   "source": [
    "## Vectorize the review data \n",
    "The text is vectorized using TfidfVectorizer, which uses the Term Frequency-Inverse Document-Frequency (TF-IDF) weighting scheme to weight each word based on its importance. `max_features` is set to 10,000 to reduce dimensionality. `stop_words` removes common English words. `ngram_range = (1, 2)` captures both one and two word features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21444085-d5e3-45d8-b2d5-ab90b28ce8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "vectorizer = TfidfVectorizer(max_features = 10000, stop_words = 'english', \n",
    "                             ngram_range = (1, 2)) \n",
    "\n",
    "X_train = vectorizer.fit_transform(data_train['review']) \n",
    "X_test = vectorizer.transform(data_test['review'])\n",
    "\n",
    "y_train = data_train.label.values\n",
    "y_test = data_test.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a3a4d6-c464-42ef-96fe-25bf1006bbcf",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "First, the data is trained using a logistic regression model. This model is simple and does not capture advanced features (sarcasm, long-range features, etc), but typical effective for this type of problem. The parameters `C = 1` controls the regularization strength. I chose an optimal value through some trial-and-error. Overall, this model is 88% effective, which is a good baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b5e0c7-7271-4eee-8978-843d81bc4a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "clf = LogisticRegression(max_iter = 1000, C = 1) \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd006c9-11fd-40f2-b0fd-5640fe66de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score:\", clf.score(X_train, y_train))\n",
    "print(\"Test score:\", clf.score(X_test, y_test))\n",
    "y_pred = clf.predict(X_test) \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6f8b5e-0418-41d7-b7d6-df7655fcf740",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize = [5, 4], layout = 'tight')\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='viridis', ax = ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571145f8-0284-4382-9f6d-65da3c3c5d02",
   "metadata": {},
   "source": [
    "## Random Forest \n",
    "The random forest captures nonlinear relationships/interactions better than the linear regression, but can struggle with sparse data like text, and can require additional tuning to avoid overfitting. The model has an accuracy of 85%, which is still decent though it may not be the optimal model for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfa9518-7adb-49e2-a1bb-a72a87f94f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100, random_state = 4)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa4892d-4c36-47ba-87c3-14cfaec7914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score:\", clf.score(X_train, y_train))\n",
    "print(\"Test score:\", clf.score(X_test, y_test))\n",
    "y_pred = clf.predict(X_test) \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0984354f-e8fc-4671-b936-6989b9000894",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize = [5, 4], layout = 'tight')\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='viridis', ax = ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010efd42-e9be-4791-ba5a-f03a1fa3e720",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "The Naive Bayes model makes the \"naive\" assumption that the phrases are conditionally independent given the class label. It is simple and efficient, though potentially at the cost of accuracy. This model achieves 85% accuracy, which is decent given the simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54109dd-9b73-401e-ac0f-d19b9c5cac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b92be0-b1c2-44b3-9c27-f9eda67a0360",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score:\", clf.score(X_train, y_train))\n",
    "print(\"Test score:\", clf.score(X_test, y_test))\n",
    "y_pred = clf.predict(X_test) \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6985f66c-77fd-4afb-adf1-aadc8ad9b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize = [5, 4], layout = 'tight')\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='viridis', ax = ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2694f7-e4b8-4145-a454-45def3a23e97",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM) \n",
    "SVM models are accurate on text classification because they are optimized for high-dimensional sparce data, though they may be computationally more intensive compared to the linear regression. For this small dataset, the computation time is not an issue, and the model achieves 88% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb8de74-1177-473a-b607-e6abf1b70742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(C = 0.1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8092f4b7-2497-4926-a6f6-3802c8392c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score:\", clf.score(X_train, y_train))\n",
    "print(\"Test score:\", clf.score(X_test, y_test))\n",
    "y_pred = clf.predict(X_test) \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f7ef84-af6e-4821-9b37-7623bc35fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize = [5, 4], layout = 'tight')\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='viridis', ax = ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1947b70-b600-4531-9f9a-2b794e4a48bf",
   "metadata": {},
   "source": [
    "# Summary\n",
    "These four classical ML algorithms provide a baseline for classification of IMDb reviews. The Linear Regression and SVM models achieve an accuracy of 88%, which is a good baseline for these classical models. More advanced tuning could increase this accuracy be a few percent. Unsurprisingly, the Naive Bayes and Random Forest models perform slightly worse, at 85% accuracy. However, this is still a decent result given their limitations. The next step is to move to a deep learning framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fbfbb8-f8ba-4628-ae5b-a3f1d78a7d12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
