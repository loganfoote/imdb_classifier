{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86fb4954-5fcd-4502-bd93-3a234b673a37",
   "metadata": {},
   "source": [
    "# IMDb Sentiment Classification - Deep Learning Approach\n",
    "Here the IMDb sentiment classification project is extended to a deep learning approach. First, an LSTM model is used with default parameters as a baseline. This initial test achieves a validation accuracy of 69%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a2d4a-33fa-40b2-a3bb-544475c1987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imdb_classification.data import load_imdb_data\n",
    "from imdb_classification.data_dl import IMDbSentimentLSTM, seed_everything\n",
    "from imdb_classification.data_dl import create_loaders, train_model, plot_training\n",
    "\n",
    "seed_everything(4)\n",
    "data_dir = 'imdb_classifier/data/' # Replace\n",
    "data_train = load_imdb_data(data_dir, subset = 'train')\n",
    "data_test = load_imdb_data(data_dir, subset = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3d3d5a-92a5-4841-aeed-be78ffcbeb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 200\n",
    "batch_size = 32 \n",
    "train_fraction = 0.8\n",
    "embed_dim = 100 \n",
    "hidden_dim = 128\n",
    "num_layers = 1\n",
    "dropout = 0.3\n",
    "\n",
    "train_loader, val_loader, word2idx =\\\n",
    "create_loaders(data_train, max_len = max_len, batch_size = batch_size, \n",
    "                   train_fraction = train_fraction)\n",
    "\n",
    "model = IMDbSentimentLSTM(word2idx = word2idx, embed_dim = embed_dim, \n",
    "                          hidden_dim = hidden_dim, num_layers = num_layers, \n",
    "                          dropout = dropout, glove = False, \n",
    "                          bidirectional = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2adb796-6579-444c-82ab-5231b4cad074",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' # 5-10X faster on GPU on the computer this was tested on\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "\n",
    "history = train_model(model, train_loader, val_loader = val_loader, \n",
    "                      epochs = epochs, lr = lr, device = device, printout = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1774c66c-849b-4fdf-aaa5-aaab76649b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab46f22f-56bf-480e-b117-a255b77d6207",
   "metadata": {},
   "source": [
    "# GloVe\n",
    "The model is rebuilt using embeddings from [GloVe](https://nlp.stanford.edu/projects/glove/), which relate similar words to one another. This speeds up the initial few epochs of learning, but ultimately does not improve the final validation accuracy meaningfully.\n",
    "Some things I learned by changing parameters:\n",
    "<ul>\n",
    "    <li>Decreasing hidden_dim to look for simpler/more general features did not change the behavior meaningfully on its own.</li>\n",
    "    <li> Increasing dropout from 0.3 to 0.5 did not make a meaningful difference.</li>\n",
    "    <li>Decreasing the learning rate from 0.001 to 0.0005 does not make a meaningful difference on its own.</li>\n",
    "    <li>Switching to a bidirectional LSTM does not make a meaningful difference on its own.</li>\n",
    "    <li>Lowering the learning rate to 0.0005 in combination with decreasing hidden_dim to 64 does not make a meaningful difference.</li>\n",
    "    <li>Lower the learning rate to 0.0005 in combination with increasing dropout to 0.5 doesn't meaningfully change the behavior.</li>\n",
    "    <li> Lowering the learning rate to 0.0005 and increasing dropout to 0.5 and decreasing `hidden_dim` to 64 does not meaningfully change the behavior. </li>\n",
    "    <li> Mean pooling does not meaningfully change the behavior. </li>\n",
    "    <li> Increasing the number of layers to 2 does not meaningfully change the behavior. </li>\n",
    "</ul>\n",
    "The best validation accuracy this model is able to achieve is 84%. The parameter optimization sped up the training to just a couple epochs, but did not improve the overall accuracy. The parameters are left in the state that achieves this accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8f6d6c-35d3-40f9-bf07-a6d80fbac6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imdb_classification.data import load_imdb_data\n",
    "from imdb_classification.data_dl import IMDbSentimentLSTM, seed_everything\n",
    "from imdb_classification.data_dl import create_loaders, train_model, plot_training\n",
    "\n",
    "seed_everything(4)\n",
    "data_dir = 'imdb_classifier/data/' # replace\n",
    "glove_path = 'imdb_classifier/data/glove.6B.100d.txt' # replace\n",
    "data_train = load_imdb_data(data_dir, subset = 'train')\n",
    "data_test = load_imdb_data(data_dir, subset = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d2b81-858c-42a9-bfe3-5ae3dbab4d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 200\n",
    "batch_size = 32 \n",
    "train_fraction = 0.8\n",
    "embed_dim = 100 \n",
    "hidden_dim = 32 \n",
    "num_layers = 2 \n",
    "dropout = 0.5\n",
    "bidirectional = True\n",
    "pool = True\n",
    "\n",
    "train_loader, val_loader, word2idx =\\\n",
    "create_loaders(data_train, max_len = max_len, batch_size = batch_size, \n",
    "                   train_fraction = train_fraction)\n",
    "\n",
    "model = IMDbSentimentLSTM(word2idx = word2idx, embed_dim = embed_dim, \n",
    "                          hidden_dim = hidden_dim, num_layers = num_layers, \n",
    "                          dropout = dropout, glove = True, pool = pool,\n",
    "                          glove_path = glove_path, bidirectional = bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acadd97c-0d63-49c2-b37c-100e59a8621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' # 5-10x faster on GPU than CPU on the computer this was tested on\n",
    "epochs = 10\n",
    "lr = 1e-3 \n",
    "\n",
    "history = train_model(model, train_loader, val_loader = val_loader, \n",
    "                      epochs = epochs, lr = lr, device = device, printout = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a096b98c-5878-4f35-8c3e-fd0d0f49202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_training(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c26ffc3-8e88-4c28-919c-685378de04b4",
   "metadata": {},
   "source": [
    "# Run evaluation on test dataset\n",
    "The model achieves 82% accuracy on the test dataset, not far from the 84% accuracy it achieves on the validation dataset. Further fine-tuning could boost these numbers by a few percent, but overall it seems that order 85% accuracy is about the limit of what this model can achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c46fd-d02a-451a-b36a-d83ae53de893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imdb_classification.data_dl import IMDbDataset, evaluate_model\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "test_dataset = IMDbDataset(data_test, max_len = 200, word2idx = word2idx)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "criterion = torch.nn.BCEWithLogitsLoss() # binary criterion\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685a7d29-61f0-4c1e-bf0a-334e4a637b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = evaluate_model(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
